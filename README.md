# Airflow 3 + Cosmos + dbt + Snowflake Demo

This repository provides a comprehensive demo project illustrating the integration of:

- **Apache Airflow 3.0** - Modern workflow orchestration
- **Astronomer Cosmos** - dbt integration for Airflow
- **dbt (Data Build Tool)** - SQL-based data transformation
- **Snowflake** - Cloud data warehouse

## üèóÔ∏è Project Structure

```
af3_cosmos/
‚îú‚îÄ‚îÄ dags/                           # Airflow DAG definitions
‚îÇ   ‚îú‚îÄ‚îÄ dbt_snowflake_dag.py       # Main dbt DAG with manifest loading
‚îÇ   ‚îî‚îÄ‚îÄ dbt_manifest_verification.py # Manifest validation DAG
‚îú‚îÄ‚îÄ dbt/snowflake_demo/             # dbt project
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ staging/                # Staging layer models
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ marts/                  # Data mart models  
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ example/                # Example dbt models
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sequential/             # Sequential processing models
‚îÇ   ‚îú‚îÄ‚îÄ target/                     # dbt compiled artifacts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ manifest.json          # Pre-compiled dbt manifest
‚îÇ   ‚îî‚îÄ‚îÄ dbt_project.yml            # dbt project configuration
‚îú‚îÄ‚îÄ db-prerequisites/              # Database setup prerequisites
‚îÇ   ‚îî‚îÄ‚îÄ snowflake_setup.sql        # Snowflake database setup script
‚îú‚îÄ‚îÄ tests/                          # Test files
‚îú‚îÄ‚îÄ requirements.txt                # Python dependencies
|-- Dockerfile                      # Container definition
```

## üöÄ Key Features

### Multiple DAG Patterns
- **Full Project DAG**: Runs all dbt models with manifest loading
- **Manifest Verification**: Validates dbt manifest integrity
> More patterns coming soon! Feel free to fork and contribute via PR.

### Advanced Cosmos Configuration
- **Manifest Loading**: Uses pre-compiled `manifest.json` for faster task generation
- **Snowflake Integration**: Native Snowflake profile mapping
- **Local Execution**: Direct dbt execution without virtual environments
- **DBT Runner Mode**: Optimized performance with `InvocationMode.DBT_RUNNER`

### dbt Project Structure
- **Layered Architecture**: Staging ‚Üí Marts data flow
- **Sequential Models**: 10-step data processing pipeline
- **Schema Testing**: Data quality validation
- **Snowflake Optimized**: Designed for Snowflake-specific features

## üìã Prerequisites

1. **Snowflake Account**: Active Snowflake warehouse
2. **Astronomer CLI**: For local development
3. **Docker**: Container runtime
4. **Snowflake Connection**: Configured in Airflow

## üóÑÔ∏è Snowflake Database Setup

Before running the dbt models through Airflow, you need to set up your Snowflake database with the required source data.

### Quick Setup

1. **Execute the setup script**: Run the SQL commands in `db-prerequisites/snowflake_setup.sql` in your Snowflake environment. This script will:
   - Create the `SAMPLE_DB` database
   - Create `RAW` and `ANALYTICS` schemas
   - Create and populate the `orders` table with sample data
   - Create and populate the `customers` table (optional, for future use)
   

## üéØ DAG Configuration Highlights

### Manifest-Based Rendering
```python
render_config = RenderConfig(
    load_method=LoadMode.DBT_MANIFEST,
)
```

### Snowflake Profile Mapping
```python
profile_config = ProfileConfig(
    profile_name="snowflake_demo",
    target_name="dev",
    profile_mapping=SnowflakeUserPasswordProfileMapping(
        conn_id="snowflake_default",
        profile_args={"schema": "ANALYTICS", "threads": 4}
    )
)
```

### Optimized Execution
```python
execution_config = ExecutionConfig(
    execution_mode=ExecutionMode.LOCAL,
    invocation_mode=InvocationMode.DBT_RUNNER
)
```

## üîç Available DAGs

1. **dbt_snowflake_cosmos_dag_1**: Main production DAG
2. **dbt_manifest_verification**: CI/CD validation

## üìö Explore More

- **[Astronomer Cosmos Documentation](https://astronomer.github.io/astronomer-cosmos/)** ‚Üí Comprehensive guide for dbt + Airflow integration
- **[Astronomer Cosmos Source Code](https://github.com/astronomer/astronomer-cosmos)** ‚Üí Latest features, examples, and community contributions